{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A seguir, apresento um exemplo detalhado – em Python – de como você pode resolver o problema de localização usando as bases fornecidas. Neste exemplo, usaremos dois métodos:\n",
        "\n",
        "1. **Método Básico (referência): k‑Nearest Neighbors (kNN)**  \n",
        "2. **Método Avançado: Random Forest**\n",
        "\n",
        "O roteiro geral do script é:\n",
        "\n",
        "1. **Importar as bibliotecas necessárias**  \n",
        "2. **Ler os dados de treinamento, teste e de BTS**  \n",
        "3. **Pré-processamento e definição das features**  \n",
        "4. **Dividir a base de treinamento em treino/validação (usaremos 10% para avaliação dos erros)**  \n",
        "5. **Treinar o modelo kNN (método básico) e o modelo Random Forest (método avançado)**  \n",
        "6. **Avaliar os modelos na base de validação – calcular métricas (erro médio, mínimo, máximo e desvio-padrão) e gerar os gráficos: histograma, box-plot e scatter plot comparando as posições reais e preditas**  \n",
        "7. **Usar o melhor modelo para gerar as predições na base de teste e salvar os resultados no arquivo de submissão (seguindo o layout de *submit_alunos.csv*)**\n",
        "\n",
        "Veja abaixo um exemplo de script comentado:\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "# 1. Importando as bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import math\n",
        "\n",
        "# 2. Função para calcular a distância entre dois pontos geográficos (usando a fórmula de Haversine)\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Calcula a distância em metros entre dois pontos definidos por latitude e longitude.\n",
        "    \"\"\"\n",
        "    # Conversão de graus para radianos\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    # Diferenças\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    # Fórmula de Haversine\n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    # Raio da Terra (m)\n",
        "    r = 6371000\n",
        "    return c * r\n",
        "\n",
        "# 3. Leitura dos dados\n",
        "# Supondo que os arquivos estejam na mesma pasta do script com os seguintes nomes:\n",
        "train_df = pd.read_csv('meds_train_alunos.csv')\n",
        "test_df = pd.read_csv('meds_test_alunos.csv')\n",
        "bts_df = pd.read_csv('Bts.csv')  # Pode ser usado para análises adicionais se necessário\n",
        "\n",
        "# 4. Pré-processamento e definição das features\n",
        "# Seleciona as colunas de sinais (RSSI) e delays conforme especificação\n",
        "features = ['rssi_1_1', 'rssi_1_2', 'rssi_1_3',\n",
        "            'rssi_2_1', 'rssi_2_2', 'rssi_2_3',\n",
        "            'rssi_3_1', 'rssi_3_2', 'rssi_3_3',\n",
        "            'delay_1', 'delay_2', 'delay_3']\n",
        "\n",
        "X = train_df[features]\n",
        "# As variáveis alvo são latitude e longitude\n",
        "y = train_df[['lat', 'lon']]\n",
        "\n",
        "# 5. Dividir a base de treinamento em treino e validação (10% para validação)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# 6. Modelo 1 – k-Nearest Neighbors (método básico)\n",
        "knn = KNeighborsRegressor(n_neighbors=5)  # Pode ajustar o número de vizinhos conforme necessário\n",
        "knn.fit(X_train, y_train)\n",
        "pred_knn = knn.predict(X_val)\n",
        "\n",
        "# Calcular os erros (distância em metros) para o kNN\n",
        "errors_knn = []\n",
        "for i in range(len(y_val)):\n",
        "    actual_lat, actual_lon = y_val.iloc[i]\n",
        "    pred_lat, pred_lon = pred_knn[i]\n",
        "    error = haversine(actual_lat, actual_lon, pred_lat, pred_lon)\n",
        "    errors_knn.append(error)\n",
        "\n",
        "# Métricas do kNN\n",
        "print(\"kNN - Erro Médio:\", np.mean(errors_knn))\n",
        "print(\"kNN - Erro Mínimo:\", np.min(errors_knn))\n",
        "print(\"kNN - Erro Máximo:\", np.max(errors_knn))\n",
        "print(\"kNN - Desvio Padrão:\", np.std(errors_knn))\n",
        "\n",
        "# 7. Modelo 2 – Random Forest (método avançado)\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "pred_rf = rf.predict(X_val)\n",
        "\n",
        "# Calcular os erros (distância em metros) para o Random Forest\n",
        "errors_rf = []\n",
        "for i in range(len(y_val)):\n",
        "    actual_lat, actual_lon = y_val.iloc[i]\n",
        "    pred_lat, pred_lon = pred_rf[i]\n",
        "    error = haversine(actual_lat, actual_lon, pred_lat, pred_lon)\n",
        "    errors_rf.append(error)\n",
        "\n",
        "# Métricas do Random Forest\n",
        "print(\"Random Forest - Erro Médio:\", np.mean(errors_rf))\n",
        "print(\"Random Forest - Erro Mínimo:\", np.min(errors_rf))\n",
        "print(\"Random Forest - Erro Máximo:\", np.max(errors_rf))\n",
        "print(\"Random Forest - Desvio Padrão:\", np.std(errors_rf))\n",
        "\n",
        "# 8. Visualização dos resultados\n",
        "# Histograma dos erros para o kNN\n",
        "plt.figure()\n",
        "plt.hist(errors_knn, bins=30, edgecolor='black')\n",
        "plt.title(\"Histograma dos Erros - kNN\")\n",
        "plt.xlabel(\"Erro (metros)\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.show()\n",
        "\n",
        "# Histograma dos erros para o Random Forest\n",
        "plt.figure()\n",
        "plt.hist(errors_rf, bins=30, edgecolor='black')\n",
        "plt.title(\"Histograma dos Erros - Random Forest\")\n",
        "plt.xlabel(\"Erro (metros)\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.show()\n",
        "\n",
        "# Box-plot dos erros\n",
        "plt.figure()\n",
        "plt.boxplot([errors_knn, errors_rf], labels=['kNN', 'Random Forest'])\n",
        "plt.title(\"Box-Plot dos Erros\")\n",
        "plt.ylabel(\"Erro (metros)\")\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot: Posições reais vs. Posições preditas (exemplo com Random Forest)\n",
        "plt.figure()\n",
        "plt.scatter(y_val['lon'], y_val['lat'], color='blue', label='Real', alpha=0.6)\n",
        "plt.scatter(pred_rf[:,1], pred_rf[:,0], color='red', marker='x', label='Predito RF', alpha=0.6)\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.title(\"Comparação: Posições Reais vs. Preditadas (Random Forest)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 9. Predição na base de teste\n",
        "# A base de teste possui as mesmas features (exceto lat, lon, indoor)\n",
        "X_test = test_df[features]\n",
        "\n",
        "# Utilizando o modelo com melhor desempenho (por exemplo, Random Forest)\n",
        "pred_test = rf.predict(X_test)\n",
        "\n",
        "# Criação do DataFrame de submissão conforme o template: ponto_id, lat, lon\n",
        "submit_df = pd.DataFrame({\n",
        "    'ponto_id': test_df['ponto_id'],\n",
        "    'lat': pred_test[:, 0],\n",
        "    'lon': pred_test[:, 1]\n",
        "})\n",
        "\n",
        "# Salvando o arquivo de resultados (lembre de seguir o nome conforme especificado: Resultados_EquipeX_MetodoY.csv)\n",
        "submit_df.to_csv(\"Resultados_EquipeX_MetodoRF.csv\", index=False)\n",
        "print(\"Arquivo de submissão gerado: Resultados_EquipeX_MetodoRF.csv\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explicação Detalhada dos Passos:\n",
        "\n",
        "1. **Importação e Definição da Função Haversine:**  \n",
        "   - Importamos as bibliotecas essenciais para manipulação de dados, modelagem e visualizações.\n",
        "   - A função `haversine` calcula a distância entre duas coordenadas (lat, lon) em metros, permitindo avaliar o erro dos modelos de localização.\n",
        "\n",
        "2. **Leitura dos Dados:**  \n",
        "   - São lidos os arquivos CSV contendo a base de treinamento (*meds_train_alunos.csv*), a base de teste (*meds_test_alunos.csv*) e os dados das BTS (*Bts.csv*). Esses dados são fundamentais para treinar e avaliar o modelo.\n",
        "\n",
        "3. **Pré-processamento:**  \n",
        "   - Selecionamos as colunas referentes aos níveis de sinal (RSSI) e aos atrasos (delay), que serão usados como variáveis de entrada (features).\n",
        "   - As variáveis alvo são a latitude e longitude dos pontos de medição da base de treinamento.\n",
        "\n",
        "4. **Divisão em Treino/Validação:**  \n",
        "   - Separamos 10% dos dados de treinamento para avaliar o desempenho dos modelos (cálculo dos erros em metros).\n",
        "\n",
        "5. **Treinamento dos Modelos:**  \n",
        "   - **kNN:** É implementado como uma técnica básica de referência. Após o treinamento, as predições para a base de validação são comparadas com os valores reais.\n",
        "   - **Random Forest:** Representa um método mais avançado. Também é treinado e suas predições são avaliadas.\n",
        "\n",
        "6. **Avaliação dos Modelos:**  \n",
        "   - Para cada modelo, calculamos o erro de localização (usando a fórmula de Haversine) e exibimos métricas (erro médio, mínimo, máximo e desvio-padrão).\n",
        "   - São gerados gráficos (histograma, box-plot e scatter plot) para visualizar a distribuição dos erros e a comparação entre as posições reais e preditas.\n",
        "\n",
        "7. **Predição para a Base de Teste e Geração do Arquivo de Submissão:**  \n",
        "   - Utilizando o modelo com melhor desempenho (neste exemplo, optamos pelo Random Forest), realizamos as predições na base de teste.\n",
        "   - Os resultados são salvos em um arquivo CSV com o formato exigido, contendo as colunas: *ponto_id, lat, lon*.\n",
        "\n",
        "Este script serve como um guia completo – desde a leitura dos dados até a geração dos resultados – e pode ser adaptado conforme as necessidades e os ajustes dos parâmetros dos modelos. Assim, você consegue testar diferentes abordagens e analisar os erros de localização de forma detalhada.\n",
        "\n",
        "---\n",
        "\n",
        "Este exemplo contempla as diretrizes mínimas da especificação do projeto e pode ser estendido, por exemplo, para incluir a análise dos dados de BTS ou outras técnicas de localização e avaliação (como o uso de IA generativa para expansão da base de dados)."
      ],
      "metadata": {
        "id": "WLC5iS_9R9v0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IKZXgic0SALn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}